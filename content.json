{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"ABS压力测试","text":"安装1yum -y install httpd-tools 检测1ab -V 123This is ApacheBench, Version 2.3 &lt;$Revision: 1430300 $&gt;Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/Licensed to The Apache Software Foundation, http://www.apache.org/ ab参数说明有关ab命令的使用，我们可以通过帮助命令进行查看。如下： 1ab --help 下面我们对这些参数，进行相关说明。如下： -n在测试会话中所执行的请求个数。默认时，仅执行一个请求。 -c一次产生的请求个数。默认是一次一个。 -t测试所进行的最大秒数。其内部隐含值是-n 50000，它可以使对服务器的测试限制在一个固定的总时间以内。默认时，没有时间限制。 -p包含了需要POST的数据的文件。 -P对一个中转代理提供BASIC认证信任。用户名和密码由一个:隔开，并以base64编码形式发送。无论服务器是否需要(即, 是否发送了401认证需求代码)，此字符串都会被发送。 -T POST数据所使用的Content-type头信息。 -v设置显示信息的详细程度-4或更大值会显示头信息，3或更大值可以显示响应代码(404,200等),2或更大值可以显示警告和其他信息。 -V显示版本号并退出。 -w以HTML表的格式输出结果。默认时，它是白色背景的两列宽度的一张表。 -i执行HEAD请求，而不是GET。 -x设置属性的字符串。 -X对请求使用代理服务器。 -y设置属性的字符串。 -C对请求附加一个Cookie:行。其典型形式是name=value的一个参数对，此参数可以重复。 -H对请求附加额外的头信息。此参数的典型形式是一个有效的头信息行，其中包含了以冒号分隔的字段和值的对(如,”Accept-Encoding:zip/zop;8bit”)。 -A对服务器提供BASIC认证信任。用户名和密码由一个:隔开，并以base64编码形式发送。无论服务器是否需要(即,是否发送了401认证需求代码)，此字符串都会被发送。 -h显示使用方法。 -d不显示”percentage served within XX [ms] table”的消息(为以前的版本提供支持)。 -e产生一个以逗号分隔的(CSV)文件，其中包含了处理每个相应百分比的请求所需要(从1%到100%)的相应百分比的(以微妙为单位)时间。由于这种格式已经“二进制化”，所以比’gnuplot’格式更有用。 -g把所有测试结果写入一个’gnuplot’或者TSV(以Tab分隔的)文件。此文件可以方便地导入到Gnuplot,IDL,Mathematica,Igor甚至Excel中。其中的第一行为标题。 -i执行HEAD请求，而不是GET。 -k启用HTTP KeepAlive功能，即在一个HTTP会话中执行多个请求。默认时，不启用KeepAlive功能。 -q如果处理的请求数大于150，ab每处理大约10%或者100个请求时，会在stderr输出一个进度计数。此-q标记可以抑制这些信息。 ab性能指标在进行性能测试过程中有几个指标比较重要： 1、吞吐率（Requests per second） 服务器并发处理能力的量化描述，单位是reqs/s，指的是在某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。 记住：吞吐率是基于并发用户数的。这句话代表了两个含义： a、吞吐率和并发用户数相关 b、不同的并发用户数下，吞吐率一般是不同的 计算公式：总请求数/处理完成这些请求数所花费的时间，即 Request per second=Complete requests/Time taken for tests 必须要说明的是，这个数值表示当前机器的整体性能，值越大越好。 2、并发连接数（The number of concurrent connections） 并发连接数指的是某个时刻服务器所接受的请求数目，简单的讲，就是一个会话。 3、并发用户数（Concurrency Level） 要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。在HTTP/1.1下，IE7支持两个并发连接，IE8支持6个并发连接，FireFox3支持4个并发连接，所以相应的，我们的并发用户数就得除以这个基数。 4、用户平均请求等待时间（Time per request） 计算公式：处理完成所有请求数所花费的时间/（总请求数/并发用户数），即： Time per request=Time taken for tests/（Complete requests/Concurrency Level） 5、服务器平均请求等待时间（Time per request:across all concurrent requests） 计算公式：处理完成所有请求数所花费的时间/总请求数，即： Time taken for/testsComplete requests 可以看到，它是吞吐率的倒数。 同时，它也等于用户平均请求等待时间/并发用户数，即 Time per request/Concurrency Level ab实际使用ab的命令参数比较多，我们经常使用的是-c和-n参数。 ab -c 10 -n 100 http://www.xxx.com/index.php -c10表示并发用户数为10 -n100表示请求总数为100 http://www.xxx.com/index.php表示请求的目标URL 这行表示同时处理100个请求并运行10次index.php文件。","link":"/2019/07/30/AB压力测试工具/"},{"title":"ABS执行原理","text":"在多线程并发的时候吧，第一个线程拿到了锁，其他线程则会在获取不到锁的时候被加到一个双向链表中排队，并且自旋循环，等到他的他的前一个节点变成头并且自己获取到锁的时候就会停止自旋","link":"/2019/07/11/AQS原理/"},{"title":"Dubbo","text":"【什么是 dubbo】Dubbo 是阿里巴巴开发用来用来治理服务中间件，资源调度和治理中心的管理工具。 【ZooKeeper 节点类型】ZooKeeper 节点是有生命周期的，这取决于节点的类型，在 ZooKeeper 中，节点类型可以分为： 持久节点（PERSISTENT ）是指在节点创建后，就一直存在，直到有删除操作来主动清除这个节点 临时节点（EPHEMERAL）临时节点的生命周期和客户端会话绑定。如果客户端会话失效，那么这个节点就会自动被清除掉。在临时节点下面不能创建子节点。 持久顺序节点（PERSISTENT_SEQUENTIAL）在持久节点的基础上，在ZK中，每个父节点会为他的第一级子节点维护一份时序，会记录每个子节点创建的先后顺序 临时顺序节点（EPHEMERAL_SEQUENTIAL）可以用来实现分布式锁【从构建分布式秒杀系统聊聊分布式锁】 【dubbo节点角色说明】 Provider: 暴露服务的服务提供方（service 服务层）。 Consumer: 调用远程服务的服务消费方(web 表现层)。 Registry: 服务注册与发现的注册中心（zookeeper）。 Monitor: 统计服务的调用次调和调用时间的监控中心。 Container: 服务运行容器(tomcat 容器，spring 容器)。 【dubbo的注册原理】zookeeper流程 服务提供者启动时向/dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址。 服务消费者启动时订阅/dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。 并向/dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址。 监控中心启动时订阅/dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。 【注册中心包括】 Multicast 注册中心不需要启动任何中心节点，只要广播地址一样，就可以互相发现。 Zookeeper 是 Apacahe Hadoop 的子项目，是一个树型的目录服务，支持变更推送，适合作为 Dubbo 服务的注册中心，工业强度较高，可用于生产环境，并推荐使用 基于 Redis 实现的注册中心 Simple 注册中心本身就是一个普通的 Dubbo 服务，可以减少第三方依赖，使整体通讯方式一致。 【dubbo,zookeeper流程,从生产者到消费者】 生产者和消费者都要进行dubbo的配置 ,都需要注册zookeeper主机地址, 生产者要配置dubbo使用的协议(默认dubbo)和端口号用来暴露服务, 生产者定义接口和实现类,并在配置文件中进行注册服务, 生产者启动时会自动把注册的接口的信息转化为一个url, 并通过hessian二进制序列化存储到zookeeper的节点中 消费者在配置文件中引入要使用的服务接口, 消费者启动时会从zookeeper中获取与引用的接口匹配的url, 并把自己的信息留在zookeeper中 服务者和消费者在zookeeper中的信息都会被监控中心monitor获取到, 可以通过monitor服务对zookeeper中的内容进行管理 【服务的配置】123456789101112131415161718&lt;!--【服务者】 给服务起一个名称,唯一标识,用来监控服务器调用关系,调用次数 --&gt;&lt;dubbo:application name=\"provider\" /&gt;&lt;!-- 使用dubbo官方推荐注册中心模式注册对象 --&gt;&lt;dubbo:registry address=\"zookeeper://192.168.1.180:2181\" /&gt;&lt;!-- 用dubbo协议在20880端口暴露服务 --&gt;&lt;dubbo:protocol name=\"dubbo\" port=\"20880\" /&gt;&lt;!-- 发布服务:itemService 注册对象,通过接口来注册对象 --&gt;&lt;!-- 和本地bean一样实现服务 --&gt;&lt;bean id=\"xxx.xxx.xxx.XxxImpl\" class=\"xxx.xxx.xxx.XxxImpl\" /&gt;&lt;dubbo:service interface=\"xxx.xxx.xxx.Ixxx\" ref=\"xxxImpl\" /&gt;&lt;!-- 【消费者】给服务起一个名称,唯一标识,用来监控服务器调用关系,调用次数 --&gt;&lt;!-- 消费方应用名，用于计算依赖关系，不是匹配条件，不要与提供方一样 --&gt;&lt;dubbo:application name=\"consumer\" /&gt;&lt;!-- 使用multicast广播注册中心暴露发现服务地址 --&gt;&lt;dubbo:registry address=\"zookeeper://192.168.17.129:2181\" /&gt;&lt;!-- 生成远程服务代理，可以和本地bean一样使用itemService --&gt;&lt;dubbo:reference id=\"xxx\" interface=\"xxx.xxx.xxx.Ixxx\" timeout=\"1000000\" retries=\"2\"/&gt; 文档http://dubbo.apache.org/zh-cn/docs/dev/design.html","link":"/2019/07/30/Dubbo/"},{"title":"Dubbo知识精华","text":"1、默认使用的是什么通信框架，还有别的选择吗?默认也推荐使用netty框架，还有mina。 2、服务调用是阻塞的吗？默认是阻塞的，可以异步调用，没有返回值的可以这么做。 3、一般使用什么注册中心？还有别的选择吗？推荐使用zookeeper注册中心，还有redis等不推荐。 4、默认使用什么序列化框架，你知道的还有哪些？默认使用Hessian序列化，还有Duddo、FastJson、Java自带序列化。 5、服务提供者能实现失效踢出是什么原理？服务失效踢出基于zookeeper的临时节点原理。 6、服务上线怎么不影响旧版本？采用多版本开发，不影响旧版本。 7、如何解决服务调用链过长的问题？可以结合zipkin实现分布式服务追踪。 8、说说核心的配置有哪些？核心配置有 123456789101112131415dubbo:service/dubbo:reference/dubbo:protocol/dubbo:registry/dubbo:application/dubbo:provider/dubbo:consumer/dubbo:method/ 9、dubbo推荐用什么协议？默认使用dubbo协议。 10、同一个服务多个注册的情况下可以直连某一个服务吗？可以直连，修改配置即可，也可以通过telnet直接某个服务。 11、Dubbo集群容错怎么做？读操作建议使用Failover失败自动切换，默认重试两次其他服务器。写操作建议使用Failfast快速失败，发一次调用失败就立即报错。 12、dubbo和dubbox之间的区别？dubbox是当当网基于dubbo上做了一些扩展，如加了服务可restful调用，更新了开源组件等。 13、你还了解别的分布式框架吗？别的还有spring的spring cloud，facebook的thrift，twitter的finagle等。 14、dubbo中zookeeper做注册中心，如果注册中心集群都挂掉，那发布者和订阅者还能通信吗?可以的，zookeeper的信息会缓存到本地作为一个缓存文件，并且转换成properties对象方便使用。 12&lt;!-- 使用zookeeper注册中心暴露服务地址 subscribe 默认：true 是否向此注册中心订阅服务，如果设为false，将只注册，不订阅 check 默认：true 注册中心不存在时，是否报错 --&gt;&lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;${dubbo.registry.address}&quot; file=&quot;${dubbo.registry.file}&quot; check=&quot;false&quot;/&gt; 12dubbo.registry.address=172.16.1.130:2181,172.16.1.133:2181,172.16.1.120:2181dubbo.registry.file=/root/.dubbo/pay/dubbo.cache 15、项目中有使用过多线程吗?有的话讲讲你在哪里用到了多线程?12345&lt;!-- 生产者配置 生产者 远程默认调用3次 参数 retries=&quot;2&quot; async=&quot;true&quot; 异步返回结果 默认是同步 timeout=&quot;10000&quot; 毫秒 用dubbo协议在20882端口暴露服务 固定线程池 10 启动时建立线程，不关闭，一直持有 负载均衡策略 轮询 --&gt;&lt;dubbo:provider timeout=&quot;10000&quot; threads=&quot;10&quot; threadpool=&quot;fixed&quot; loadbalance=&quot;roundrobin&quot;/&gt; 16、Zookeeper的Java客户端你使用过哪些?","link":"/2019/07/30/Dubbo知识精华/"},{"title":"jps","text":"列出PID和Java主类名1234jps2017 Bootstrap2576 Jps 列出pid和java完整主类名1234jps -l2017 org.apache.catalina.startup.Bootstrap2612 sun.tools.jps.Jps 列出pid、主类全称和应用程序参数1234jps -lm2017 org.apache.catalina.startup.Bootstrap start2588 sun.tools.jps.Jps -lm 列出pid和JVM参数12345jps -v2017 Bootstrap -Djava.util.logging.config.file=/usr/local/tomcat-web/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Dfile.encoding=UTF-8 -Xms256m -Xmx1024m -XX:PermSize=256m -XX:MaxPermSize=512m -verbose:gc -Xloggc:/usr/local/tomcat-web/logs/gc.log-2014-02-07 -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xnoclassgc -Djava.endorsed.dirs=/usr/local/tomcat-web/endorsed -Dcatalina.base=/usr/local/tomcat-web -Dcatalina.home=/usr/local/tomcat-web -Djava.io.tmpdir=/usr/local/tomcat-web/temp2624 Jps -Dapplication.home=/usr/lib/jvm/jdk1.6.0_43 -Xms8m 和【ps -ef | grep java】类似的输出1234jps -lvm2017 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=/usr/local/tomcat-web/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Dfile.encoding=UTF-8 -Xms256m -Xmx1024m -XX:PermSize=256m -XX:MaxPermSize=512m -verbose:gc -Xloggc:/usr/local/tomcat-web/logs/gc.log-2014-02-07 -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xnoclassgc -Djava.endorsed.dirs=/usr/local/tomcat-web/endorsed -Dcatalina.base=/usr/local/tomcat-web -Dcatalina.home=/usr/local/tomcat-web -Djava.io.tmpdir=/usr/local/tomcat-web/temp2645 sun.tools.jps.Jps -lvm -Dapplication.home=/usr/lib/jvm/jdk1.6.0_43 -Xms8m","link":"/2019/07/30/JPS-Java进程状态工具/"},{"title":"Linux 系统监控工具","text":"1.vmstat - 虚拟内存统计 vmstat 命令报告有关进程、内存、分页、块 IO、中断和 CPU 活动等信息。 1# vmstat 3 输出示例： 123456789procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------ r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 2540988 522188 5130400 0 0 2 32 4 2 4 1 96 0 0 1 0 0 2540988 522188 5130400 0 0 0 720 1199 665 1 0 99 0 0 0 0 0 2540956 522188 5130400 0 0 0 0 1151 1569 4 1 95 0 0 0 0 0 2540956 522188 5130500 0 0 0 6 1117 439 1 0 99 0 0 0 0 0 2540940 522188 5130512 0 0 0 536 1189 932 1 0 98 0 0 0 0 0 2538444 522188 5130588 0 0 0 0 1187 1417 4 1 96 0 0 0 0 0 2490060 522188 5130640 0 0 0 18 1253 1123 5 1 94 0 0 2.找出占用内存资源最多的前 10 个进程 1ps -auxf | sort -nr -k 4 | head -10 3.找出占用 CPU 资源最多的前 10 个进程 1ps -auxf | sort -nr -k 3 | head -10","link":"/2019/07/30/Linux 系统监控工具/"},{"title":"Linux中find常见用法示例","text":"Linux中find常见用法示例 ·find path -option [ -print ] [ -exec -ok command ] {} ; find命令的参数； pathname: find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。-print： find命令将匹配的文件输出到标准输出。-exec： find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为’command’ { } ;，注意{ }和\\；之间的空格。-ok： 和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 #-print 将查找到的文件输出到标准输出 #-exec command {} ; —–将查到的文件执行command操作,{} 和 ;之间有空格 #-ok 和-exec相同，只不过在操作前要询用户 原文：https://www.cnblogs.com/archoncap/p/6144369.html","link":"/2019/07/30/Linux中find常见用法示例/"},{"title":"Linux 常用命令","text":"查看某个文件夹的总容量 1du -sh","link":"/2019/07/30/Linux常用命令/"},{"title":"Linux查看进程运行的完整路径方法","text":"通过ps及top命令查看进程信息时，只能查到相对路径，查不到的进程的详细信息，如绝对路径等。这时，我们需要通过以下的方法来查看进程的详细信息： /procLinux在启动一个进程时，系统会在/proc下创建一个以PID命名的文件夹，在该文件夹下会有我们的进程的信息，其中包括一个名为exe的文件即记录了绝对路径，通过ll或ls –l命令即可查看。 1ll /proc/PID 比如，我们查看mongo使用以下命令： 123[root@rmpapp local]# ps -ef|grep mongoroot 9466 6380 0 13:41 pts/1 00:00:00 grep --color=auto mongoroot 16053 1 0 8月14 ? 06:45:52 ./mongod --config mongodb.conf 然后： 1ll /proc/16053","link":"/2019/07/30/Linux查看进程运行的完整路径方法/"},{"title":"Linux查看进程运行的完整路径方法","text":"通常情况下我们需要在两个Linux服务器之间拷贝文件，比如定时备份。 以博客为例，网站目录定时打包比如一周或者一个月，远程同步到备份服务器。 博客服务器输入一下命令，然后输入远程主机密码，即可进行同步拷贝： 1scp -r /mnt/domains/blog.52itstyle.com_20181024.tar.gz root@115.29.143.135:/home/backups/ 如果想增量拷贝，我们可以使用rsync命令。 1rsync -avz /mnt/domains/blog.52itstyle.com root@115.29.143.135:/home/backups/ 如果出现： 1RSA host key for [ip address] has changed and you have requested strict checking 可能是系统重装后，本地机和服务器内部ssh对不上导致错误，因此，只需要删除本地机ssh缓存信息，即可恢复。在本地机输入一下命令行： 1ssh-keygen -R IP","link":"/2019/07/30/Linux远程拷贝同步命令案例/"},{"title":"Mqtt协议讲解","text":"MQTT 数据包结构1MqttPublishMessage[fixedHeader=MqttFixedHeader[messageType=PUBLISH, isDup=false, qosLevel=AT_MOST_ONCE, isRetain=false, remainingLength=8], variableHeader=MqttPublishVariableHeader[topicName=test, packetId=-1], payload=PooledSlicedByteBuf(ridx: 0, widx: 2, cap: 2/2, unwrapped: PooledUnsafeDirectByteBuf(ridx: 10, widx: 10, cap: 1024))] 固定头（Fixed header），存在于所有MQTT数据包中，表示数据包类型及数据包的分组类标识 可变头（Variable header），存在于部分MQTT数据包中，数据包类型决定了可变头是否存在及其具体内容 消息体（Payload），存在于部分MQTT数据包中，表示客户端收到的具体内容 固定头由2个byte组成 1个byte=8bit （这里要理清楚哪边是高位） 例如16 = 0001 0000 bit0-3 = 0000 retain = 0, qos = 00, dup = 0 ） 第一个byte 分为8bit bit0-bit3表示 bit0 = retain(发布保留标识，表示服务器要保留这次推送的信息，如果有新的订阅者出现，就把这消息推送给它，如果设有那么推送至当前订阅者后释放。) bit1-2 = qos 发布消息的服务质量，即：保证消息传递的次数 00：最多一次，即：&lt;=1 01：至少一次，即：&gt;=1 10：一次，即：=1 11：预留 bit3 = dup (发布消息的副本。用来在保证消息的可靠传输，如果设置为 1，则在下面的变长中增加MessageId，并且需要回复确认，以保证消息传输完成，但不能用于检测消息重复发送。) bit4-7 消息类型 （例如16 = 0001 0000 bit4-7 = 0001 = 1 = CONNECT ） 名称 值 流方向 描述 Reserved 0 不可用 保留位 CONNECT 1 客户端到服务器 客户端请求连接到服务器 CONNACK 2 服务器到客户端 连接确认 PUBLISH 3 双向 发布消息 PUBACK 4 双向 发布确认 PUBREC 5 双向 发布收到（保证第1部分到达） PUBREL 6 双赂 发布释放（保证第2部分到达） PUBCOMP 7 双向 发布完成（保证第3部分到达） SUBSCRIBE 8 客户端到服务器 客户端请求订阅 SUBACK 9 服务器到客户端 订阅确认 UNSUBSCRIBE 10 客户端到服务器 请求取消订阅 UNSUBACK 11 服务器到客户端 取消订阅确认 PINGREQ 12 客户端到服务器 PING请求 PINGRESP 13 服务器到客户端 PING应答 DISCONNECT 14 客户端到服务器 中断连接 Reserved 15 不可用 保留位 第二个byte 消息的长度最终结构 Description 7 6 5 4 3 2 1 0 Fixed header/固定头部 Message Type(1) DUP flag QoS level RETAIN byte 1 0 0 0 1 x x x x byte 2 Remaining Length Variable header/可变头部 Protocol Name byte 1 Length MSB (0) 0 0 0 0 0 0 0 0 byte 2 Length LSB (6) 0 0 0 0 0 1 1 0 byte 3 &apos;M&apos; 0 1 0 0 1 1 0 1 byte 4 &apos;Q&apos; 0 1 0 1 0 0 0 1 byte 5 &apos;I&apos; 0 1 0 0 1 0 0 1 byte 6 &apos;s&apos; 0 1 1 1 0 0 1 1 byte 7 &apos;d&apos; 0 1 1 0 0 1 0 0 byte 8 &apos;p&apos; 0 1 1 1 0 0 0 0 Protocol Version Number byte 9 Version (3) 0 0 0 0 0 0 1 1 Connect Flags User Name Flag Password Flag Will Retain Will QoS Will Flag Clean Session Reserved byte 10 1 1 0 0 1 1 1 x Keep Alive timer byte 11 Keep Alive MSB (0) 0 0 0 0 0 0 0 0 byte 12 Keep Alive LSB (10) 0 0 0 0 1 0 1 0 Playload/消息体 Client Identifier(客户端ID) 1-23个字符长度，客户端到服务器的全局唯一标志，如果客户端ID超出23个字符长度，服务器需要返回码为2，标识符被拒绝响应的CONNACK消息。 处理QoS级别1和2的消息ID中，可以使用到。 必填项。 Will Topic Will Flag值为1，这里便是Will Topic的内容。QoS级别通过Will QoS字段定义，RETAIN值通过Will RETAIN标识，都定义在可变头里面。 Will Message Will Flag若设为1，这里便是Will Message定义消息的内容，对应的主题为Will Topic。如果客户端意外的断开触发服务器PUBLISH此消息。 长度有可能为0。 在CONNECT消息中的Will Message是UTF-8编码的，当被服务器发布时则作为二进制的消息体。 User Name 如果设置User Name标识，可以在此读取用户名称。一般可用于身份验证。协议建议用户名为不多于12个字符，不是必须。 Password 如果设置Password标识，便可读取用户密码。建议密码为12个字符或者更少，但不是必须。","link":"/2019/07/26/Mqtt/"},{"title":"mysql","text":"注意事项不要听信你看到的关于优化的“绝对真理”，包括本文所讨论的内容，而应该是在实际的业务场景下通过测试来验证你关于执行计划以及响应时间的假设。 单条查询最后添加 LIMIT 1，停止全表扫描。 对于char(4) 或者vachar(4)，无论是中文还是英文都是存储四个字符，注意是字符而不是字节。 如果一个字段未int类型，此类型只有0、1两个状态，需要为此建立索引吗？过度索引，影响更新速度，必须在唯一性较高的字段上建立非聚集索引。 在创建表的时候如果在业务中能保证非null的字段，建议明确标示not null 因为mysql中对null需要特殊的标示。使用not null 字段更节省空间。对接下来的索引构建也有好处。 count() 和count(name) name 代表某个字段，可以为NULL。在mysql中count()会把null统计进去、而count(name) 不会。如果统计的字段中含有null，这个两个统计的结果是不同的。 在sql语句等号左边用函数，会使该查询在该字段无法使用索引。如LENGTH(str) 函数。 索引也是需要存储到物理空间的，经常增删的表不适合建太多的索引，因为索引的维护会很耗时间。一张表最多建立15个索引。索引的长度越小越好，索引是有序的。如果查询Max（）之类用索引的话，连表都不用查询了，快得飞起。 mysql中null不参与比较运算，name &lt;&gt;’小米’ 得出的结果中不包含 name=null的情况。在业务不能保证某字段是否为null的情况，写代码的时候需要注意null的坑。保证取得的数据是对而全，然后再考虑查询速率问题。 MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。 对整数类型指定宽度，比如INT(11)，没有任何卵用。INT使用32位（4个字节）存储空间，那么它的表示范围已经确定，所以INT(1)和INT(20)对于存储和计算是相同的。 UNSIGNED表示不允许负值，大致可以使正数的上限提高一倍。比如TINYINT存储范围是-128 ~ 127，而UNSIGNED TINYINT存储的范围却是0 - 255。 通常来讲，没有太大的必要使用DECIMAL数据类型。即使是在需要存储财务数据时，仍然可以使用BIGINT。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用BIGINT存储。这样可以避免浮点数计算不准确和DECIMAL精确计算代价高的问题。 TIMESTAMP使用4个字节存储空间，DATETIME使用8个字节存储空间。因而，TIMESTAMP只能表示1970 - 2038年，比DATETIME表示的范围小得多，而且TIMESTAMP的值因时区不同而不同。 schema的列不要太多。原因是存储引擎的API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，这个转换过程的代价是非常高的。如果列太多而实际使用的列又很少的话，有可能会导致CPU占用过高。 大表ALTER TABLE非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。","link":"/2019/07/30/MySQL/"},{"title":"mysql分库分表","text":"某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么?他们的原理知道么？数据千万级别之多，占用的存储空间也比较大，可想而知它不会存储在一块连续的物理空间上，而是链式存储在多个碎片的物理空间上。可能对于长字符串的比较，就用更多的时间查找与比较，这就导致用更多的时间。 可以做表拆分，减少单表字段数量，优化表结构。 在保证主键有效的情况下，检查主键索引的字段顺序，使得查询语句中条件的字段顺序和主键索引的字段顺序保持一致。 主要两种拆分 垂直拆分，水平拆分。 垂直分表也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。 垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。 切分后，要放在多个服务器上，而不是一个服务器上。为什么？ 我们想象一下，一个购物网站对外提供服务，会有用户，商品，订单等的CRUD。没拆分之前， 全部都是落到单一的库上的，这会让数据库的单库处理能力成为瓶颈。按垂直分库后，如果还是放在一个数据库服务器上， 随着用户量增大，这会让单个数据库的处理能力成为瓶颈，还有单个服务器的磁盘空间，内存，tps等非常吃紧。 所以我们要拆分到多个服务器上，这样上面的问题都解决了，以后也不会面对单机资源问题。 数据库业务层面的拆分，和服务的“治理”，“降级”机制类似，也能对不同业务的数据分别的进行管理，维护，监控，扩展等。 数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于Web和应用服务器来讲，是比较难实现“横向扩展”的。 数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈。 水平分表针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。 水平分库分表 将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。 水平分库分表切分规则 RANGE从0到10000一个表，10001到20000一个表； HASH取模一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。 地理区域比如按照华东，华南，华北这样来区分业务，七牛云应该就是如此。 时间按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。 分库分表后面临的问题 事务支持分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。 跨库join 只要是进行切分，跨节点Join的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。解决这一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的id,根据这些id发起第二次请求得到关联数据。分库分表方案产品 跨节点的count,order by,group by以及聚合函数问题这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作。解决方案：与解决跨节点join问题的类似，分别在各个节点上得到结果后在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。 数据迁移，容量规划，扩容等问题来自淘宝综合业务平台团队，它利用对2的倍数取余具有向前兼容的特性（如对4取余得1的数对2取余也是1）来分配数据，避免了行级别的数据迁移，但是依然需要进行表级别的迁移，同时对扩容规模和分表数量都有限制。总得来说，这些方案都不是十分的理想，多多少少都存在一些缺点，这也从一个侧面反映出了Sharding扩容的难度。 ID问题一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一方面，某个分区数据库自生成的ID无法保证在全局上是唯一的；另一方面，应用程序在插入数据之前需要先获得ID,以便进行SQL路由.一些常见的主键生成策略 UUID使用UUID作主键是最简单的方案，但是缺点也是非常明显的。由于UUID非常的长，除占用大量存储空间外，最主要的问题是在索引上，在建立索引和基于索引进行查询时都存在性能问题。 Twitter的分布式自增ID算法Snowflake在分布式系统中，需要生成全局UID的场合还是比较多的，twitter的snowflake解决了这种需求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间41位 机器ID 10位 毫秒内序列12位。 跨分片的排序分页般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示： 中间件推荐 源自：https://www.cnblogs.com/fishlynn/p/9674793.html","link":"/2019/07/30/MySql_distributed/"},{"title":"mysql_course","text":"教程文字教程MySQL 教程（菜鸟教程） MySQL教程（易百教程） 视频教程MySQL开发技巧（一） MySQL开发技巧（二） MySQL开发技巧（三） MySQL5.7版本新特性 性能优化之MySQL优化 MySQL集群（PXC）入门 MyCAT入门及应用","link":"/2019/07/30/MySql_course/"},{"title":"mysql索引","text":"索引常用规则1、表的主键、外键必须有索引；2、数据量超过300的表应该有索引；3、经常与其他表进行连接的表，在连接字段上应该建立索引；4、经常出现在Where子句中的字段，特别是大表的字段，应该建立索引；5、索引应该建在选择性高的字段上；6、索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引；7、复合索引的建立需要进行仔细分析；尽量考虑用单字段索引代替： 正确选择复合索引中的主列字段，一般是选择性较好的字段； 复合索引的几个字段是否经常同时以AND方式出现在Where子句中？单字段查询是否 极少甚至没有？如果是，则可以建立复合索引；否则考虑单字段索引； 如果复合索引中包含的字段经常单独出现在Where子句中，则分解为多个单字段索引； 如果复合索引所包含的字段超过3个，那么仔细考虑其必要性，考虑减少复合的字段； 如果既有单字段索引，又有这几个字段上的复合索引，一般可以删除复合索引；8、频繁进行数据操作的表，不要建立太多的索引；9、删除无用的索引，避免对执行计划造成负面影响； 以上是一些普遍的建立索引时的判断依据。索引的建立必须慎重，对每个索引的必要性都应该经过仔细分析，要有建立的依据。 因为太多的索引与不充分、不正确的索引对性能都毫无益处：在表上建立的每个索引都会增加存储开销，索引对于插入、删除、更新操作也会增加处理上的开销。 另外，过多的复合索引，在有单字段索引的情况下，一般都是没有存在价值的；相反，还会降低数据增加删除时的性能，特别是对频繁更新的表来说，负面影响更大。 总的来说，小型表肯定不建索引，或者数据库记录在亿条数据级以上，还是建议使用非关系型数据库。 还有些特殊字段的数据库，比如BLOB，CLOB字段肯定也不适合建索引。 对千万级MySQL数据库建立索引的事项及提高性能的手段注意事项：首先，应当考虑表空间和磁盘空间是否足够。我们知道索引也是一种数据，在建立索引的时候势必也会占用大量表空间。因此在对一大表建立索引的时候首先应当考虑的是空间容量问题。其次，在对建立索引的时候要对表进行加锁，因此应当注意操作在业务空闲的时候进行。 性能调整方面首当其冲的考虑因素便是磁盘I/O。物理上，应当尽量把索引与数据分散到不同的磁盘上（不考虑阵列的情况）。逻辑上，数据表空间与索引表空间分开。这是在建索引时应当遵守的基本准则。其次，我们知道，在建立索引的时候要对表进行全表的扫描工作，因此，应当考虑调大初始化参数db_file_multiblock_read_count的值。一般设置为32或更大。 再次，建立索引除了要进行全表扫描外同时还要对数据进行大量的排序操作，因此，应当调整排序区的大小。 9i之前，可以在session级别上加大sort_area_size的大小，比如设置为100m或者更大。 9i以后，如果初始化参数workarea_size_policy的值为TRUE，则排序区从pga_aggregate_target里自动分配获得。最后，建立索引的时候，可以加上nologging选项。以减少在建立索引过程中产生的大量redo，从而提高执行的速度。 MySql在建立索引优化时需要注意的问题设计好MySql的索引可以让你的数据库飞起来，大大的提高数据库效率。设计MySql索引的时候有一下几点注意： 创建索引对于查询占主要的应用来说，索引显得尤为重要。很多时候性能问题很简单的就是因为我们忘了添加索引而造成的，或者说没有添加更为有效的索引导致。如果不加索引的话，那么查找任何哪怕只是一条特定的数据都会进行一次全表扫描，如果一张表的数据量很大而符合条件的结果又很少，那么不加索引会引起致命的性能下降。但是也不是什么情况都非得建索引不可，比如性别可能就只有两个值，建索引不仅没什么优势，还会影响到更新速度，这被称为过度索引。 复合索引比如有一条语句是这样的： 1select * from users where area=’beijing’ and age=22; 如果我们是在area和age上分别创建单个索引的话，由于mysql查询每次只能使用一个索引，所以虽然这样已经相对不做索引时全表扫描提高了很多效率，但是如果在area、age两列上创建复合索引的话将带来更高的效率。如果我们创建了(area, age,salary)的复合索引，那么其实相当于创建了(area,age,salary)、(area,age)、(area)三个索引，这被称为最佳左前缀特性。因此我们在创建复合索引时应该将最常用作限制条件的列放在最左边，依次递减。 索引不会包含有NULL值的列只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL。 使用短索引对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个CHAR(255)的 列，如果在前10 个或20 个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。 排序的索引问题mysql查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。 like语句操作一般情况下不鼓励使用like操作，如果非使用不可，如何使用也是一个问题。like “%a%” 不会使用索引而like “aaa%”可以使用索引。 不要在列上进行运算1select * from users where YEAR(adddate) 不使用NOT IN和操作NOT IN和操作都不会使用索引将进行全表扫描。NOT IN可以NOT EXISTS代替，id3则可使用id&gt;3 or id 参考阅读MySQL索引背后的数据结构及算法原理","link":"/2019/07/30/MySql_index/"},{"title":"mysql锁","text":"数据库锁概述相对其他数据库而言，MySQL的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。比如，MyISAM和MEMORY存储引擎采用的是表级锁（table-level locking）；InnoDB存储引擎既支持行级锁（ row-level locking），也支持表级锁，但默认情况下是采用行级锁。 MySQL主要的两种锁的特性可大致归纳如下: 表级锁： 开销小，加锁快；不会出现死锁(因为MyISAM会一次性获得SQL所需的全部锁)；锁定粒度大，发生锁冲突的概率最高,并发度最低。 行级锁： 开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 考虑上述特点，表级锁使用与并发性不高，以查询为主，少量更新的应用，比如小型的web应用；而行级锁适用于高并发环境下，对事务完整性要求较高的系统，如在线事务处理系统。 MyISAM锁细述(1). 锁模式 MySQL的表级锁有两种模式： 表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。 (2). 如何加锁 当MyISAM在执行查询语句时，会自动给涉及到表加读锁，在执行更新操作时，会加写锁。当然用户也可以用LOCK TABLE 去显式的加锁。显式的加锁一般是应用于：需要在一个时间点实现多个表的一致性读取，不然的话，可能读第一个表时，其他表由于还没进行读操作，没有自动加锁，可能数据会发生改变。并且显示加锁后只能访问加锁的表，不能访问其他表。 (3). 并发插入 MyISAM存储引擎有个系统变量 concurrent_insert，专门用来控制并发插入的行为，可以取 0 ， 1 ， 2。 0表示不允许并发插入，1表示表中间没有删除的行时可以在表末尾插入，2表示总是可以插入。 一般如果对并发要求比较高的情况下，可以设置为2，总是可以插入，然后定期在数据库空闲时间对表进行optimize。 (4). 锁的调度 需要注意的是，其中读操作不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；并且当写锁和读锁同时被申请时，优先获得写锁，这也这正是表级锁发生锁冲突概率最高的原因，因为写锁可能会一直阻塞读锁，所以不适合有大量写操作的环境下工作。这一问题可以通过设置low-priority-updates这一启动参数来降低写的优先级。虽然写锁优先于读锁获取，但是长时间的查询操作也可能会让写操作饿死，所以尽量避免一条SQL语句执行所有的查询，应该进行必要的分解。 InnoDB锁细述由于InnoDB支持事务，并默认是使用行级锁，所以InnoDB的锁问题和MyISAM锁问题还是有蛮大差别的。 (1). 锁模式 共享锁(S)和排他锁(X)，分别类似于MyISAM的读锁和写锁。对于 UPDATE、 DELETE 和 INSERT 语句，InnoDB会自动给涉及数据集加排他锁（X)；对于普通 SELECT 语句，InnoDB不会加任何锁。 (2). 如何加锁 可以显式的加锁，用lock in share mode 显式的加共享锁，用 for update 显式的加排他锁。 需要注意的是，如果线程A加了共享锁后，线程B对同一个表加了共享锁，那么两个线程需要进行更新操作时会产生死锁。所以，进行更新操作时最好加排他锁。 (3). InnoDB行锁的实现方式——索引加锁 这一点与Oracle不同，所以这也意味着(重要)：1. 只有通过索引条件检索数据时，InnoDB才会使用行级锁，否则会使用表级锁。 2. 即使是访问不同行的记录，如果使用的是相同的索引键，会发生锁冲突。 3. 如果数据表建有多个索引时，可以通过不同的索引锁定不同的行。 (4). 间隙锁 InnoDB支持事务，为了满足隔离级别的要求，InnoDB有个间隙锁，当使用范围查找时，InnoDB会给满足key范围要求，但实际并不存在的记录加锁。例如：select * from user where id &gt; 100 for updata 会给ID&gt;100的记录加排他锁，满足这个范围，但不存在的记录，会加间隙锁，这样可以避免幻读，避免读取的时候插入满足条件的记录。 (5). 隔离级别与锁 一般来说，隔离级别越高，加锁就越严格。这样，产生锁冲突的概率就越大，一般实际应用中，通过优化应用逻辑，选用 可提交读 级别就够了。对于一些确实需要更高隔离级别的事务，再通过set session transaction isolation level+”级别” 来动态改变满足需求。 死锁MyISAM是没有死锁问题的，因为他会一次性获得所有的锁。InnoDB发生死锁后一般能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。 在应用中，可以通过如下方式来尽可能的避免死锁： (1) 如果不同的程序会并发的存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。 (2) 在程序以批量方式处理数据时，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大的降低出现死锁的可能。 案例秒杀一1234## 查询库存，由于是主键查询使用到了索引，所以是行级锁SELECT number FROM seckill WHERE seckill_id=? FOR UPDATE## 如果库存大于秒杀数则更新，UPDATE 操作也是行级锁UPDATE seckill SET number=number-1 WHERE seckill_id=? 秒杀二12//直接更新数据，如果count为1秒杀成功否则失败UPDATE seckill SET number=number-1 WHERE seckill_id=? AND number&gt;0 秒杀三12345//获取商品版本号以及剩余数量SELECT version,number FROM seckill WHERE seckill_id=?//判断剩余数量是否充足并更新UPDATE seckill SET number=number-?,version=version+1 WHERE seckill_id=? AND version = ? //如果更新数量等于1秒杀成功否则失败 Mysql innodb虽是锁行的，但是如果没有索引，或者索引唯一性不是特别强，那就要锁表了。 加锁对并发访问的影响体现在锁的粒度上，可见行锁粒度最小，并发访问最好，页锁粒度最大，表锁介于2者之间。 锁有两种：悲观锁和乐观锁。悲观锁假定其他用户企图访问或者改变你正在访问、更改的对象的概率是很高的，因此在悲观锁的环境中，在你开始改变此对象之前就将该对象锁住，并且直到你提交了所作的更改之后才释放锁。悲观的缺陷是不论是页锁还是行锁，加锁的时间可能会很长，这样可能会长时间的限制其他用户的访问，也就是说悲观锁的并发访问性不好。 与悲观锁相反，乐观锁则认为其他用户企图改变你正在更改的对象的概率是很小的，因此乐观锁直到你准备提交所作的更改时才将对象锁住，当你读取以及改变该对象时并不加锁。可见乐观锁加锁的时间要比悲观锁短，乐观锁可以用较大的锁粒度获得较好的并发访问性能。但是如果第二个用户恰好在第一个用户提交更改之前读取了该对象，那么当他完成了自己的更改进行提交时，数据库就会发现该对象已经变化了，这样，第二个用户不得不重新读取该对象并作出更改。这说明在乐观锁环境中，会增加并发用户读取对象的次数。 参考https://www.cnblogs.com/zhanht/p/5431273.html https://www.cnblogs.com/liujiacai/p/7605612.html https://www.cnblogs.com/claireyuancy/p/7258314.html","link":"/2019/07/30/MySql_lock/"},{"title":"mysql小技巧","text":"MySql 小技巧1）修改默认时区select now(); 查看 MySql 系统时间。和当前时间做对比 set global time_zone = ‘+8:00’;设置时区更改为东八区 flush privileges; 刷新权限 2）批量删除以字段开头的表1234# 先查询SELECT GROUP_CONCAT(table_name) FROM information_schema.tables WHERE table_schema=&apos;itstyle&apos; AND table_name LIKE &apos;add%&apos;# 拷贝出来DROP TABLE add_student,add_teacher 3）查看所有连接进程1show full processlist 看一下所有连接进程，注意查看进程等待时间以及所处状态 是否locked 如果进程过多，就把进程打印下来，然后查看 1mysql -e &apos;show full processlist;&apos; &gt; list.txt 4）创建一个只读权限的用户123456# 创建查询用户、允许外网访问CREATE USER &apos;select&apos;@&apos;%&apos; IDENTIFIED BY &apos;123456&apos;;# 给新用户赋予查询权限GRANT SELECT ON * . * TO &apos;select&apos;@&apos;%&apos;;# 刷新权限FLUSH PRIVILEGES;","link":"/2019/07/30/MySql_skill/"},{"title":"mysql优化","text":"优化负向查询不能使用索引1select * from order where status!=0 and stauts!=1 还有 not in/not exists都不是好习惯 1select name from order where status not in (0,1); 可以优化为in查询： 1select * from order where status in(2,3) 前导模糊查询不能使用索引如: 1select name from user where name like '%xxx' 非前导则可以: 1select name from user where name like 'xxx%' MyISAM 存储引擎也可以做全文检索，不过只支持英文，相信现在应该也没人使用它了。建议使用solr 、es 等第三方开始工具实现全文检索功能。 数据区分不明显的不建议创建索引如 user 表中的性别字段，可以明显区分的才建议创建索引，如身份证等字段。 1select * from user where sex=1 原因：性别只有男，女，每次过滤掉的数据很少，不宜使用索引。 经验上，能过滤80%数据时就可以使用索引。对于订单状态，如果状态值很少，不宜使用索引，如果状态值很多，能够过滤大量数据，则应该建立索引。 字段的默认值不要为 null这样会带来和预期不一致的查询结果，建议参考注意事项。 在属性上进行计算不能命中索引1select * from order where YEAR(date) &lt; = '2017' 即使date上建立了索引，也会全表扫描，可优化为值计算： 1select * from order where date &lt; = CURDATE() 复合索引最左前缀用户中心建立了(login_name, passwd)的复合索引 123select * from user where login_name=? and passwd=?select * from user where passwd=? and login_name=? 但是使用 1select * from user where passwd=? 不能命中索引，不满足复合索引最左前缀 如果明确知道只有一条记录返回1select name from user where username='xxxx' limit 1 提高效率，可以让数据库停止游标移动，停止全表扫描。 强制类型转换会全表扫描1select * from user where phone=13800001234 这样虽然可以查出数据，但会导致索引失效。 需要修改为 1select * from user where phone='13800001234' 把计算放到业务层而不是数据库层，除了节省数据的CPU，还有意想不到的查询缓存优化效果参考引用58沈剑 架构师之路","link":"/2019/07/30/MySql_optimization/"},{"title":"mysql事务","text":"事务的基本要素（ACID） 原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。 一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。 隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。 持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。 事务的并发问题 脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据 不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致。 幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表 MySQL事务隔离级别 事务隔离级别 脏读 不可重复读 幻读 读未提交（read-uncommitted） 是 是 是 不可重复读（read-committed） 否 是 是 可重复读（repeatable-read） 否 否 是 串行化（serializable） 否 否 否 mysql默认的事务隔离级别为repeatable-read 1SELECT @@tx_isolation","link":"/2019/07/30/MySql_trasaction/"},{"title":"nginx参数配置","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#运行用户user nobody;#启动进程,通常设置成和cpu的数量相等worker_processes 1;#全局错误日志及PID文件#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;#工作模式及连接数上限events { #epoll是多路复用IO(I/O Multiplexing)中的一种方式, #仅用于linux2.6以上内核,可以大大提高nginx的性能 use epoll; #单个后台worker process进程的最大并发链接数 worker_connections 1024; # 并发总数是 worker_processes 和 worker_connections 的乘积 # 即 max_clients = worker_processes * worker_connections # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4 为什么 # 为什么上面反向代理要除以4，应该说是一个经验值 # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000 # worker_connections 值的设置跟物理内存大小有关 # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数 # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右 # 我们来看看360M内存的VPS可以打开的文件句柄数是多少： # $ cat /proc/sys/fs/file-max # 输出 34336 # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内 # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置 # 使得并发总数小于操作系统可以打开的最大文件数目 # 其实质也就是根据主机的物理CPU和内存进行配置 # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。 # ulimit -SHn 65535}http { #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定日志格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， #以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; #开启gzip压缩 gzip on; gzip_disable &quot;MSIE [1-6].&quot;; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4 128k; #设定虚拟主机配置 server { #侦听80端口 listen 80; #定义使用 www.nginx.cn访问 server_name www.nginx.cn; #定义服务器的默认网站根目录位置 root html; #设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; #默认请求 location / { #定义首页索引文件的名称 index index.php index.html index.htm; } # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html { } #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ { #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; } #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置. location ~ .php$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } #禁止访问 .htxxx 文件 location ~ /.ht { deny all; } }}","link":"/2019/07/30/Nginx参数配置说明/"},{"title":"mysql进阶","text":"静态文件服务器在Java开发过程以及生产环境中，最常用的web应用服务器当属Tomcat，尽管这只猫也能够处理一些静态请求，例如图片、html、样式文件等，但是效率并不是那么尽人意。所以在生产环境中，我们一般使用Nginx代理服务器来处理静态文件，来提升网站性能。 12345678910111213server { listen 80; server_name file.52itstyle.com; charset utf-8; #root 指令用来指定文件在服务器上的基路径 root /data/statics; #location指令用来映射请求到本地文件系统 location / { autoindex on; # 索引 autoindex_exact_size on; # 显示文件大小 autoindex_localtime on; # 显示文件时间 } } 负载均衡Nginx 提供轮询（round robin）、IP 哈希（client IP）和加权轮询 3 种方式，默认情况下，Nginx 采用的是轮询。 轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 1234upstream backserver { server 192.168.1.14; server 192.168.1.15; } 加权轮询指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 1234upstream backserver { server 192.168.1.14 weight=1; server 192.168.1.15 weight=2; } ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 12345upstream backserver { ip_hash; server 192.168.0.14; server 192.168.0.15; } 重试策略可以为每个 backserver 指定最大的重试次数，和重试时间间隔,所使用的关键字是 max_fails 和 fail_timeout。 1234upstream backserver { server 192.168.1.14 weight=1 max_fails=2 fail_timeout=30s; server 192.168.1.15 weight=2 max_fails=2 fail_timeout=30s;} 失败重试次数为3，且超时时间为30秒。 热机策略123456upstream backserver { server 192.168.1.14 weight=1 max_fails=2 fail_timeout=30s; server 192.168.1.15 weight=2 max_fails=2 fail_timeout=30s;server 192.168.1.16 backup;} 当所有的非备机（non-backup）都宕机（down）或者繁忙（busy）的时候，就会使用由 backup 标注的备机。必须要注意的是，backup 不能和 ip_hash 关键字一起使用。 WebSocket配置实例Nginx学习之反向代理WebSocket配置实例","link":"/2019/07/30/Nginx进阶配置/"},{"title":"Spring-batch 详解","text":"各个表的含义123456789batch_job_execution (执行任务详情，成功，失败，时间等)batch_job_execution_context ()batch_job_execution_params (执行任务的参数表)batch_job_execution_seq (序列号)batch_job_instance (执行任务记录)batch_job_seq (序列号)batch_step_execution (步奏记录表)batch_step_execution_contextbatch_step_execution_seq (序列号) 碰到的一些问题 (A job instance already exists and is complete for parameters={run.id=1}. If you want to run this job again, change the parameters.) 这个问题是同一个job只执行一遍，job会根据parameters判断是不是同一个任务，已经执行的任务就不会再执行了","link":"/2019/07/19/Spring-batch详解/"},{"title":"Tomcat实践","text":"运行模式Tomcat Connector三种运行模式（BIO, NIO, APR）的比较和优化。 1234org.apache.coyote.http11.Http11Protocol：BIOorg.apache.coyote.http11.Http11NioProtocol：NIOorg.apache.coyote.http11.Http11Nio2Protocol：NIO2org.apache.coyote.http11.Http11AprProtocol：APR BIO一个线程处理一个请求。缺点：并发量高时，线程数较多，浪费资源。Tomcat7或以下，在Linux系统中默认使用这种方式。 NIO利用Java的异步IO处理，可以通过少量的线程处理大量的请求。Tomcat8在Linux系统中默认使用这种方式。Tomcat7必须修改Connector配置来启动： 1234&lt;Connector port=\"8080\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" connectionTimeout=\"20000\" redirectPort=\"8443\"/&gt; Tomcat8以后NIO2模式： 1234&lt;Connector port=\"8080\" protocol=\"org.apache.coyote.http11.Http11Nio2Protocol\" connectionTimeout=\"20000\" redirectPort=\"8443\"/&gt; APR即Apache Portable Runtime，从操作系统层面解决io阻塞问题。Tomcat7或Tomcat8在Win7或以上的系统中启动默认使用这种方式。Linux如果安装了apr和native，Tomcat直接启动就支持apr。 连接池默认值： 12&lt;Executor name=\"tomcatThreadPool\" namePrefix=\"catalina-exec-\" maxThreads=\"150\" minSpareThreads=\"4\"/&gt; 修改为： 12345678&lt;Executor name=\"tomcatThreadPool\" namePrefix=\"catalina-exec-\" maxThreads=\"500\" minSpareThreads=\"100\" prestartminSpareThreads = \"true\" maxQueueSize = \"100\"/&gt; 参数解释： maxThreads，最大并发数，默认设置 200，一般建议在 500 ~ 800，根据硬件设施和业务来判断 minSpareThreads，Tomcat 初始化时创建的线程数，默认设置 25 prestartminSpareThreads，在 Tomcat 初始化的时候就初始化 minSpareThreads 的参数值，如果不等于 true，minSpareThreads 的值就没啥效果了 maxQueueSize，最大的等待队列数，超过则拒绝请求 默认的链接参数配置： 123456&lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; 修改为： 12345&lt;Connector executor=\"tomcatThreadPool\" port=\"8080\" protocol=\"org.apache.coyote.http11.Http11Nio2Protocol\" connectionTimeout=\"20000\" redirectPort=\"8443\"/&gt; 参数解释： protocol，Tomcat 8 设置 nio2 更好：org.apache.coyote.http11.Http11Nio2Protocol protocol，Tomcat 6、7 设置 nio 更好：org.apache.coyote.http11.Http11NioProtocol enableLookups，禁用DNS查询 acceptCount，指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理，默认设置 100 maxPostSize，以 FORM URL 参数方式的 POST 提交方式，限制提交最大的大小，默认是 2097152(2兆)，它使用的单位是字节。10485760 为 10M。如果要禁用限制，则可以设置为 -1 acceptorThreadCount，用于接收连接的线程的数量，默认值是1。一般这个指需要改动的时候是因为该服务器是一个多核CPU，如果是多核 CPU 一般配置为 2 端口配置Tomcat服务器需配置三个端口才能启动，安装时默认启用了这三个端口，当要运行多个tomcat服务时需要修改这三个端口。 12&lt;!-- 端口-1即可，标识随机 --&gt;&lt;Server port=\"-1\" shutdown=\"SHUTDOWN\"&gt; 12345&lt;!-- 访问端口，必须配置 --&gt;&lt;Connector port=\"8080\" protocol=\"org.apache.coyote.http11.Http11Nio2Protocol\" connectionTimeout=\"20000\" redirectPort=\"8443\"/&gt; 12&lt;!-- 配置Apache使用，如果使用Nginx代理注释掉即可 --&gt;&lt;Connector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; JVM 优化Java 的内存模型分为： Young，年轻代（易被 GC）。Young 区被划分为三部分，Eden 区和两个大小严格相同的 Survivor 区，其中 Survivor 区间中，某一时刻只有其中一个是被使用的，另外一个留做垃圾收集时复制对象用，在 Young 区间变满的时候，minor GC 就会将存活的对象移到空闲的Survivor 区间中，根据 JVM 的策略，在经过几次垃圾收集后，任然存活于 Survivor 的对象将被移动到 Tenured 区间。 Tenured，终身代。Tenured 区主要保存生命周期长的对象，一般是一些老的对象，当一些对象在 Young 复制转移一定的次数以后，对象就会被转移到 Tenured 区，一般如果系统中用了 application 级别的缓存，缓存中的对象往往会被转移到这一区间。 Perm，永久代。主要保存 class,method,filed 对象，这部门的空间一般不会溢出，除非一次性加载了很多的类，不过在涉及到热部署的应用服务器的时候，有时候会遇到 java.lang.OutOfMemoryError : PermGen space 的错误，造成这个错误的很大原因就有可能是每次都重新部署，但是重新部署后，类的 class 没有被卸载掉，这样就造成了大量的 class 对象保存在了 perm 中，这种情况下，一般重新启动应用服务器可以解决问题。 Linux 修改 /tomcat/bin/catalina.sh 文件，把下面信息添加到文件第一行。 机子内存如果是 8G，一般 PermSize 配置是主要保证系统能稳定起来就行： 1JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms6144m -Xmx6144m -XX:NewSize=1024m -XX:MaxNewSize=2048m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot; 参数说明： 1234567891011-Dfile.encoding：默认文件编码-server：表示这是应用于服务器的配置，JVM 内部会有特殊处理的-Xmx1024m：设置JVM最大可用内存为1024MB-Xms1024m：设置JVM最小内存为1024m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。-XX:NewSize：设置年轻代大小-XX:MaxNewSize：设置最大的年轻代大小-XX:PermSize：设置永久代大小-XX:MaxPermSize：设置最大永久代大小-XX:NewRatio=4：设置年轻代（包括 Eden 和两个 Survivor 区）与终身代的比值（除去永久代）。设置为 4，则年轻代与终身代所占比值为 1：4，年轻代占整个堆栈的 1/5-XX:MaxTenuringThreshold=10：设置垃圾最大年龄，默认为：15。如果设置为 0 的话，则年轻代对象不经过 Survivor 区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在 Survivor 区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。-XX:+DisableExplicitGC：这个将会忽略手动调用 GC 的代码使得 System.gc() 的调用就会变成一个空调用，完全不会触发任何 GC","link":"/2019/07/30/Tomcat最佳实践/"},{"title":"Zookeeper","text":"","link":"/2019/07/30/Zookeeper/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/07/04/hello-world/"},{"title":"Hexo+Gitpages 搭建流程","text":"首先安装 nodejs npm -version 出现版本，则安装成功 安装 hexo-cli 1npm install -g hexo-cli 创建目录 1mkdir hexo_blog 初始化hexo 1hexo init hexo_blog 进入目录 1cd hexo_blog 5 . 安装 1npm install 启动hexo 服务 (访问localhost:4000 成功则ok) 1hexo server 修改配置文件 （_config.yml） Theme目录下面deploy:type: gitrepo: https://github.com/467812367/467812367.github.io.gitbranch: master 安装部署插件 1npm install hexo-deployer-git 部署到github上 1hexo d 先清除，后部署 (清除部署)（要输入账户密码） 1hexo clean &amp;&amp; hexo d","link":"/2019/07/30/hexo+gitpages/"},{"title":"top","text":"linux下用top命令查看cpu利用率超过100%，这里显示的所有的cpu加起来的使用率，说明你的CPU是多核，你运行top后按大键盘1看看，可以显示每个cpu的使用率，top里显示的是把所有使用率加起来。 按下1后可以看到我的机器的CPU是双核的。%Cpu0，%Cpu1，%Cpu2…… 这里我们也可以查看一下CPU信息：在命令行里输入：cat /proc/cpuinfo 这里可以看到cpu cores : 11","link":"/2019/07/30/linux下用top命令查看cpu利用率超过100%/"},{"title":"Linux查看进程运行的完整路径方法","text":"linux SSH默认端口是22，不修改的话存在一定的风险，要么是被人恶意扫描，要么会被人破解或者攻击，所以我们需要修改默认的SSH端口。 1vi /etc/ssh/sshd_config 默认端口是22，并且已经被注释掉了，打开注释修改为其他未占用端口即可。 开启防火墙端口并重复服务即可。 1systemctl restart sshd.service","link":"/2019/07/30/linux如何修改默认SSH端口/"},{"title":"基本常识 （转）","text":"API与SPI分离框架或组件通常有两类客户，一个是使用者，一个是扩展者，API(Application Programming Interface)是给使用者用的，而SPI(Service Provide Interface)是给扩展者用的，在设计时，尽量把它们隔离开，而不要混在一起，也就是说，使用者是看不到扩展者写的实现的，比如：一个Web框架，它有一个API接口叫Action， 里面有个execute()方法，是给使用者用来写业务逻辑的，然后，Web框架有一个SPI接口给扩展者控制输出方式， 比如用velocity模板输出还是用json输出等，如果这个Web框架使用一个都继承Action的VelocityAction和一个JsonAction做为扩展方式，要用velocity模板输出的就继承VelocityAction，要用json输出的就继承JsonAction，这就是API和SPI没有分离的反面例子，SPI接口混在了API接口中，合理的方式是，有一个单独的Renderer接口，有VelocityRenderer和JsonRenderer实现，Web框架将Action的输出转交给Renderer接口做渲染输出。 服务域/实体域/会话域分离任何框架或组件，总会有核心领域模型，比如： Spring的Bean，Struts的Action，Dubbo的Service，Napoli的Queue等等这个核心领域模型及其组成部分称为实体域，它代表着我们要操作的目标本身，实体域通常是线程安全的，不管是通过不变类，同步状态，或复制的方式，服务域也就是行为域，它是组件的功能集，同时也负责实体域和会话域的生命周期管理，比如Spring的ApplicationContext，Dubbo的ServiceManager等， 服务域的对象通常会比较重，而且是线程安全的，并以单一实例服务于所有调用， 什么是会话？就是一次交互过程，会话中重要的概念是上下文，什么是上下文？ 比如我们说：“老地方见”，这里的“老地方”就是上下文信息，为什么说“老地方”对方会知道，因为我们前面定义了“老地方”的具体内容， 所以说，上下文通常持有交互过程中的状态变量等，会话对象通常较轻，每次请求都重新创建实例，请求结束后销毁。简而言之： 把元信息交由实体域持有， 把一次请求中的临时状态由会话域持有， 由服务域贯穿整个过程。 在重要的过程上设置拦截接口如果你要写个远程调用框架，那远程调用的过程应该有一个统一的拦截接口，如果你要写一个ORM框架，那至少SQL的执行过程，Mapping过程要有拦截接口，如果你要写一个Web框架，那请求的执行过程应该要有拦截接口， 等等，没有哪个公用的框架可以Cover住所有需求，允许外置行为，是框架的基本扩展方式， 这样，如果有人想在远程调用前，验证下令牌，验证下黑白名单，统计下日志，如果有人想在SQL执行前加下分页包装，做下数据权限控制，统计下SQL执行时间，如果有人想在请求执行前检查下角色，包装下输入输出流，统计下请求量， 等等，就可以自行完成，而不用侵入框架内部， 拦截接口，通常是把过程本身用一个对象封装起来，传给拦截器链，比如：远程调用主过程为invoke()，那拦截器接口通常为invoke(Invocation)，Invocation对象封装了本来要执行过程的上下文，并且Invocation里有一个invoke()方法，由拦截器决定什么时候执行，同时，Invocation也代表拦截器行为本身，这样上一拦截器的Invocation其实是包装的下一拦截器的过程，直到最后一个拦截器的Invocation是包装的最终的invoke()过程，同理，SQL主过程为execute()，那拦截器接口通常为execute(Execution)，原理一样， 当然，实现方式可以任意，上面只是举例。 重要的状态的变更发送事件并留出监听接口这里先要讲一个事件和上面拦截器的区别，拦截器是干预过程的，它是过程的一部分，是基于过程行为的， 而事件是基于状态数据的，任何行为改变的相同状态，对事件应该是一致的，事件通常是事后通知，是一个Callback接口，方法名通常是过去式的，比如onChanged()，比如远程调用框架，当网络断开或连上应该发出一个事件，当出现错误也可以考虑发出一个事件，这样外围应用就有可能观察到框架内部的变化，做相应适应。 扩展接口职责尽可能单一，具有可组合性比如，远程调用框架它的协议是可以替换的， 如果只提供一个总的扩展接口，当然可以做到切换协议， 但协议支持是可以细分为底层通讯，序列化，动态代理方式等等，如果将接口拆细，正交分解，会更便于扩展者复用已有逻辑，而只是替换某部分实现策略， 当然这个分解的粒度需要把握好。 微核插件式，平等对待第三方大凡发展的比较好的框架，都遵守微核的理念， Eclipse的微核是OSGi，Spring的微核是BeanFactory，Maven的微核是Plexus， 通常核心是不应该带有功能性的，而是一个生命周期和集成容器， 这样各功能可以通过相同的方式交互及扩展，并且任何功能都可以被替换， 如果做不到微核，至少要平等对待第三方，即原作者能实现的功能，扩展者应该可以通过扩展的方式全部做到，原作者要把自己也当作扩展者，这样才能保证框架的可持续性及由内向外的稳定性。 不要控制外部对象的生命周期比如上面说的Action使用接口和Renderer扩展接口， 框架如果让使用者或扩展者把Action或Renderer实现类的类名或类元信息报上来，然后在内部通过反射newInstance()创建一个实例， 这样框架就控制了Action或Renderer实现类的生命周期，Action或Renderer的生老病死，框架都自己做了，外部扩展或集成都无能为力，好的办法是让使用者或扩展者把Action或Renderer实现类的实例报上来，框架只是使用这些实例，这些对象是怎么创建的，怎么销毁的，都和框架无关， 框架最多提供工具类辅助管理，而不是绝对控制。 可配置一定可编程，并保持友好的CoC约定因为使用环境的不确定因素很多，框架总会有一些配置， 一般都会到classpath直扫某个指定名称的配置，或者启动时允许指定配置路径， 做为一个通用框架，应该做到凡是能配置文件做的一定要能通过编程方式进行，否则当使用者需要将你的框架与另一个框架集成时就会带来很多不必要的麻烦，另外，尽可能做一个标准约定，如果用户按某种约定做事时，就不需要该配置项。比如：配置模板位置，你可以约定，如果放在templates目录下就不用配了， 如果你想换个目录，就配置下。 区分命令与查询，明确前置条件与后置条件这个是契约式设计的一部分，尽量遵守有返回值的方法是查询方法，void返回的方法是命令，询方法通常是幂等性的，无副作用的，也就是不改变任何状态，调n次结果都是一样的，比如get某个属性值，或查询一条数据库记录， 命令是指有副作用的，也就是会修改状态，比如set某个值，或update某条数据库记录， 如果你的方法即做了修改状态的操作，又做了查询返回，如果可能，将其拆成写读分离的两个方法， 比如：User deleteUser(id)，删除用户并返回被删除的用户，考虑改为getUser()和void的deleteUser()。 另外，每个方法都尽量前置断言传入参数的合法性，后置断言返回结果的合法性，并文档化。","link":"/2019/07/30/一些设计上的基本常识 - 梁飞/"},{"title":"知识图谱","text":"阅读源码阅读、分析源码是程序员最基本的码代码能力也是码农的根本所在，学习经典源码中所用到的经典设计思想及常用设计模式，能够帮你了解大牛是如何写代码的，从而吸收大牛的代码功力。 分布式架构阿里巴巴有很多大团队，这种大团队里有很多小团队，到小团队之后，做的业务都不相同，如果想立足成为一线互联网公司中的万能选手，最主流的分布式架构中有很多知识都是必须要去了解与学习的。并且在阿里面试过程中，面试官会问到实际应用场景的问题：比如微服务化、用户量、并发量、业务复杂度以及可扩展程度等，这里不多赘述。 微服务架构微服务是现在互联网架构技术中最火热的话题之一，作为一名开发者，一名有技术梦想的程序员微服务架构是现在必须要去了解的主流技术。 并发编程并发编程几乎是所有互联网公司面试必问问题，并发编程是Java程序员最重要的技能之一，也是最难掌握的一种技能。它要求编程者对计算机最底层的运作原理有深刻的理解，同时要求编程者逻辑清晰、思维缜密，这样才能写出高效、安全、可靠的多线程并发程序。 性能优化性能一直是让程序员比较头疼的问题。当系统架构变得复杂而庞大之后，性能方面就会下降，特别是阿里巴巴这样的一线互联网公司最为注重，因此想进入阿里，性能优化一定是要去深入学习与理解的一环。 Java开发工具一名开发人员必须有适合自己的兵器，也就是工欲善其事必先利其器，不管是小白，还是资深开发，都需要先选择好的工具。 更多IT架构师技术知识图谱：http://file.52itstyle.com","link":"/2019/07/30/知识图谱/"},{"title":"ActiveMQ 教程","text":"ActiveMQ的一些特性和参数 AUTO_ACKNOWLEDGE = 1 自动确认 CLIENT_ACKNOWLEDGE = 2 客户端手动确认 DUPS_OK_ACKNOWLEDGE = 3 自动批量确认 SESSION_TRANSACTED = 0 事务提交并确认 INDIVIDUAL_ACKNOWLEDGE = 4 单条消息确认 activemq 独有 ActiveMQ 到底是推还是拉？ ActiveMQ默认是主动给consumer推送消息，默认到1000条consumer还未消费完就停止推送了。直到小于1000条，就会自动推送。 如果想要让consumer主动去拉，得把prefetchSize设置为0（默认1000），之后才能主动去拉 1Destination destination = session.createQueue(\"test-queue?consumer.prefetchSize=0\"); queue 和 topic 区别queue的特性 消息生产者生产消息发送到queue中，然后消息消费者从queue中取出并且消费消息。消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费、其它的则不能消费此消息了。当消费者不存在时，消息会一直保存，直到有消费消费 支持集群消费队列消息，开启多个消费者即可 topic的特性 消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。当生产者发布消息，不管是否有消费者。都不会保存消息，意味着用户如果离线，消息再也不会被收到 只有创建durableSubscriber（持久化的订阅者）才会保存消息，用户离线了再上线，还是可以收到消息 不支持集群消费，开启多个消费者都能分别收到同样的消息，如何给每个消费者设置同一个ClientId的话，则只有一个能连上。 activemq的一些玩法① 可以一次性往多个主题或者队列里发送数据 生产者代码： 1234567891011121314151617ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"admin\", \"password\", url);Connection connection = null;try { connection = connectionFactory.createConnection(); connection.start(); Session session = connection.createSession(NON_TRANSACTED, Session.AUTO_ACKNOWLEDGE); Destination destination = session.createQueue(\"test-queue,test-queue-foo,test-queue-bar,topic://test-topic-foo\"); MessageProducer producer = session.createProducer(destination); for (int i = 0; i &lt; NUM_MESSAGES_TO_SEND; i++) { TextMessage message = session.createTextMessage(\"Message #\" + i); System.out.println(\"Sending message #\" + i); producer.send(message); Thread.sleep(DELAY); } 消费者代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263try { connection = connectionFactory.createConnection(); connection.start(); Session session = connection.createSession(NON_TRANSACTED, Session.AUTO_ACKNOWLEDGE); Destination destination = session.createQueue(\"test-queue\"); Destination destinationFoo = session.createQueue(\"test-queue-foo\"); Destination destinationBar = session.createQueue(\"test-queue-bar\"); Destination destinationTopicFoo = session.createTopic(\"test-topic-foo\"); MessageConsumer consumer = session.createConsumer(destination); MessageConsumer consumerFoo = session.createConsumer(destinationFoo); MessageConsumer consumerBar = session.createConsumer(destinationBar); MessageConsumer consumerTopicFoo = session.createConsumer(destinationTopicFoo); int i = 0; while (true) { Message message = consumer.receive(TIMEOUT); if (message != null) { if (message instanceof TextMessage) { String text = ((TextMessage) message).getText(); System.out.println(\"Got \" + i++ + \". message on test-queue: \" + text); } } else { break; } message = consumerFoo.receive(TIMEOUT); if (message != null) { if (message instanceof TextMessage) { String text = ((TextMessage) message).getText(); System.out.println(\"Got \" + i++ + \". message on test-queue-foo: \" + text); } } else { break; } message = consumerBar.receive(TIMEOUT); if (message != null) { if (message instanceof TextMessage) { String text = ((TextMessage) message).getText(); System.out.println(\"Got \" + i++ + \". message on test-queue-bar: \" + text); } } else { break; } message = consumerTopicFoo.receive(TIMEOUT); if (message != null) { if (message instanceof TextMessage) { String text = ((TextMessage) message).getText(); System.out.println(\"Got \" + i++ + \". message on test-topic-bar: \" + text); } } else { break; } } ②创建一个持久性的订阅者 1234567891011121314151617181920212223try { System.setProperty(\"clientId\",\"jiangwz\"); connection = connectionFactory.createConnection(); String clientId = System.getProperty(\"clientId\"); System.out.println(clientId); connection.setClientID(clientId); connection.start(); Session session = connection.createSession(NON_TRANSACTED, Session.AUTO_ACKNOWLEDGE); Topic destination = session.createTopic(\"test-topic\"); MessageConsumer consumer = session.createDurableSubscriber(destination, clientId) ; consumer.setMessageListener(new Subscriber(latch)); latch.await(); consumer.close(); session.close();} catch (Exception e) { System.out.println(\"Caught exception!\");} ③队列排他消费 默认情况下一个队列多个消费者会出现负载均衡的状况，如果你想只让一个消费者消费，其他消费者都消费不到消息，只要在队列后面加上?consumer.exclusive=true就可以了（只有第一个消费的人能够消费到，先来先消费），可以看如下代码： 1234567891011121314151617181920212223242526272829try { connection = connectionFactory.createConnection(); connection.start(); Session session = connection.createSession(NON_TRANSACTED, Session.AUTO_ACKNOWLEDGE); Queue destination = session.createQueue(\"test-queue?consumer.exclusive=true\"); MessageConsumer consumer = session.createConsumer(destination); int i = 0; while (true) { Message message = consumer.receive(TIMEOUT); if (message != null) { if (message instanceof TextMessage) { String text = ((TextMessage) message).getText(); System.out.println(\"Got \" + i++ + \". message: \" + text); } } else { break; } } consumer.close(); session.close();} catch (Exception e) { System.out.println(\"Caught exception!\");} ④未读消息浏览功能（browser） 只要消息未被读取（因为默认mq会把已读的消息删除掉），可以先去队列里面查看里面消息的内容 123456789101112131415161718192021try { connection = connectionFactory.createConnection(); connection.start(); Session session = connection.createSession(NON_TRANSACTED, Session.AUTO_ACKNOWLEDGE); Queue destination = session.createQueue(\"test-queue\"); QueueBrowser browser = session.createBrowser(destination); Enumeration enumeration = browser.getEnumeration(); while (enumeration.hasMoreElements()) { TextMessage message = (TextMessage) enumeration.nextElement(); System.out.println(\"Browsing: \" + message); TimeUnit.MILLISECONDS.sleep(DELAY); } session.close();} catch (Exception e) { System.out.println(\"Caught exception!\");} ⑤消息选择器（messageSelector） 发的时候可以加属性 1234567891011121314151617181920212223242526272829try { connection = connectionFactory.createConnection(); connection.start(); Session session = connection.createSession(NON_TRANSACTED, Session.AUTO_ACKNOWLEDGE); Destination destination = session.createQueue(\"test-queue\"); MessageProducer producer = session.createProducer(destination); for (int i = 0; i &lt; NUM_MESSAGES_TO_SEND; i++) { TextMessage message = session.createTextMessage(\"Message #\" + i); System.out.println(\"Sending message #\" + i); if (i % 2 == 0) { System.out.println(\"Sending to me\"); message.setStringProperty(\"intended\", \"me\"); } else { System.out.println(\"Sending to you\"); message.setStringProperty(\"intended\", \"you\"); } producer.send(message); Thread.sleep(DELAY); } producer.close(); session.close();} catch (Exception e) { System.out.println(\"Caught exception!\");} 消费的时候 可以指定 （intended = ‘you’）定向消费到you里面的消息（而不会消费到me里面的数据），不写messageSelector能消费到队列里所有数据 1234567891011121314151617181920212223242526272829try { connection = connectionFactory.createConnection(); connection.start(); Session session = connection.createSession(NON_TRANSACTED, Session.AUTO_ACKNOWLEDGE); Destination destination = session.createQueue(\"test-queue\"); MessageConsumer consumer = session.createConsumer(destination, \"intended = 'you'\"); int i = 0; while (true) { Message message = consumer.receive(TIMEOUT); if (message != null) { if (message instanceof TextMessage) { String text = ((TextMessage) message).getText(); System.out.println(\"Got \" + i++ + \". message: \" + text); } } else { break; } } consumer.close(); session.close();} catch (Exception e) { System.out.println(\"Caught exception!\");} ⑥ 临时队列 （TemporaryQueue）一般用于生产者给消费者发消息，需要消费者收到消息后，回一条消息时用到生产者代码： 123456789101112131415161718192021222324252627282930313233try { connection = connectionFactory.createConnection(); connection.start(); Session session = connection.createSession(NON_TRANSACTED, Session.AUTO_ACKNOWLEDGE); Destination destination = session.createQueue(\"test-queue\"); MessageProducer producer = session.createProducer(destination); Destination replyDest = session.createTemporaryQueue(); // set up the consumer to handle the reply MessageConsumer replyConsumer = session.createConsumer(replyDest); replyConsumer.setMessageListener(new MessageListener() { @Override public void onMessage(Message message) { System.out.println(\"*** REPLY *** \"); System.out.println(message.toString()); } }); TextMessage message = session.createTextMessage(\"I need a response for this, please\"); message.setJMSReplyTo(replyDest); producer.send(message); // wait for a response TimeUnit.SECONDS.sleep(2); producer.close(); session.close();} catch (Exception e) { System.out.println(\"Caught exception!\");} 消费者代码： 1234567891011121314151617181920212223242526272829303132try { connection = connectionFactory.createConnection(); connection.start(); final Session session = connection.createSession(NON_TRANSACTED, Session.AUTO_ACKNOWLEDGE); Destination destination = session.createQueue(\"test-queue\"); MessageConsumer consumer = session.createConsumer(destination); int i = 0; while (true) { Message message = consumer.receive(TIMEOUT); if (message != null) { if (message instanceof TextMessage) { String text = ((TextMessage) message).getText(); System.out.println(\"Got \" + i++ + \". message: \" + text); Destination replyTo = message.getJMSReplyTo(); MessageProducer producer = session.createProducer(replyTo); producer.send(session.createTextMessage(\"You made it to the consumer, here is your response\")); producer.close(); } } else { break; } } consumer.close(); session.close(); } catch (Exception e) { System.out.println(\"Caught exception!\"); } ⑦ 消费者有2中消费方法 调用receive方法阻塞获取 1Message message = consumer.receive(TIMEOUT); 设置一个监听器获取 1consumer.setMessageListener(new Subscriber(latch)); ⑧ 可以用*号 匹配所有主题进行消费 例如 /hello/* 可以匹配 /hello/1,/hello/2主题下面的所有消息 控制台密码修改 先查看jetty.xml文件里面验证有没有开启, authenticate = true 开启 123456&lt;bean id=\"securityConstraint\" class=\"org.eclipse.jetty.util.security.Constraint\"&gt; &lt;property name=\"name\" value=\"BASIC\" /&gt; &lt;property name=\"roles\" value=\"user,admin\" /&gt; &lt;!-- set authenticate=false to disable login --&gt; &lt;property name=\"authenticate\" value=\"true\" /&gt;&lt;/bean&gt; 去conf/jetty-realm.properties 里面修改用户 分别是 账户：密码，角色 1234--- Defines users that can access the web (console, demo, etc.)--- username: password [,rolename ...]root: root, adminuser: user, user 修改连接密码在 activeMQ的 activemq.xml里面的broker标签里面加入以下配置 12345678&lt;!-- 添加访问ActiveMQ的账号密码 --&gt; &lt;plugins&gt; &lt;simpleAuthenticationPlugin&gt; &lt;users&gt; &lt;authenticationUser username=&quot;admin&quot; password=&quot;admin&quot; groups=&quot;users,admins&quot;/&gt; &lt;/users&gt; &lt;/simpleAuthenticationPlugin&gt; &lt;/plugins&gt; 修改连接密码后，可能导致控制台访问异常，例如查看队列里面的消息出问题，这时一定要修改credentials.properties文件里面的账户和上面配置的密码一致 activemq.username=admin activemq.password=admin guest.password=password","link":"/2019/07/25/ActiveMQ/"},{"title":"Dubbo知识精华-2","text":"1、了解Dubbo么？Dubbo是阿里巴巴开源的基于 Java 的高性能 RPC 分布式服务框架，现已成为 Apache 基金会孵化项目。 官网：http://dubbo.apache.org 2、为什么要用Dubbo？因为是阿里开源项目，国内很多互联网公司都在用，已经经过很多线上考验。内部使用了 Netty、Zookeeper，保证了高性能高可用性。 使用 Dubbo 可以将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，可用于提高业务复用灵活扩展，使前端应用能更快速的响应多变的市场需求。 下面这张图可以很清楚的诠释，最重要的一点是，分布式架构可以承受更大规模的并发流量。 下面是 Dubbo 的服务治理图。 3、Dubbo 和 Spring Cloud 有什么区别？两个没关联，如果硬要说区别，有以下几点。 1）通信方式不同 Dubbo 使用的是 RPC 通信，而 Spring Cloud 使用的是 HTTP RESTFul 方式。 2）组成部分不同 4、dubbo都支持什么协议，推荐用哪种？dubbo://（推荐） rmi:// hessian:// http:// webservice:// thrift:// memcached:// redis:// rest:// ####/5、Dubbo需要 Web 容器吗？ 不需要，如果硬要用 Web 容器，只会增加复杂性，也浪费资源。 6、Dubbo内置了哪几种服务容器？Spring Container Jetty Container Log4j Container Dubbo 的服务容器只是一个简单的 Main 方法，并加载一个简单的 Spring 容器，用于暴露服务。 7、Dubbo里面有哪几种节点角色？ 8、画一画服务注册与发现的流程图 该图来自 Dubbo 官网，供你参考，如果你说你熟悉 Dubbo, 面试官经常会让你画这个图，记好了。 9、Dubbo默认使用什么注册中心，还有别的选择吗？推荐使用 Zookeeper 作为注册中心，还有 Redis、Multicast、Simple 注册中心，但不推荐。 10、Dubbo有哪几种配置方式？1）Spring 配置方式2）Java API 配置方式 11、Dubbo 核心的配置有哪些？我曾经面试就遇到过面试官让你写这些配置，我也是蒙逼。。 配置之间的关系见下图。 12、在 Provider 上可以配置的 Consumer 端的属性有哪些？1）timeout：方法调用超时2）retries：失败重试次数，默认重试 2 次3）loadbalance：负载均衡算法，默认随机4）actives 消费者端，最大并发调用限制 13、Dubbo启动时如果依赖的服务不可用会怎样？Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，默认 check=”true”，可以通过 check=”false” 关闭检查。 14、Dubbo推荐使用什么序列化框架，你知道的还有哪些？推荐使用Hessian序列化，还有Duddo、FastJson、Java自带序列化。 15、Dubbo默认使用的是什么通信框架，还有别的选择吗？Dubbo 默认使用 Netty 框架，也是推荐的选择，另外内容还集成有Mina、Grizzly。 16、Dubbo有哪几种集群容错方案，默认是哪种？ 17、Dubbo有哪几种负载均衡策略，默认是哪种？ 18、注册了多个同一样的服务，如果测试指定的某一个服务呢？可以配置环境点对点直连，绕过注册中心，将以服务接口为单位，忽略注册中心的提供者列表。 19、Dubbo支持服务多协议吗？Dubbo 允许配置多协议，在不同服务上支持不同协议或者同一服务上同时支持多种协议。 20、当一个服务接口有多种实现时怎么做？当一个接口有多种实现时，可以用 group 属性来分组，服务提供方和消费方都指定同一个 group 即可。 21、服务上线怎么兼容旧版本？可以用版本号（version）过渡，多个不同版本的服务注册到注册中心，版本号不同的服务相互间不引用。这个和服务分组的概念有一点类似。 22、Dubbo可以对结果进行缓存吗？可以，Dubbo 提供了声明式缓存，用于加速热门数据的访问速度，以减少用户加缓存的工作量。 23、Dubbo服务之间的调用是阻塞的吗？默认是同步等待结果阻塞的，支持异步调用。 Dubbo 是基于 NIO 的非阻塞实现并行调用，客户端不需要启动多线程即可完成并行调用多个远程服务，相对多线程开销较小，异步调用会返回一个 Future 对象。 异步调用流程图如下。 24、Dubbo支持分布式事务吗？目前暂时不支持，后续可能采用基于 JTA/XA 规范实现，如以图所示。 25、Dubbo telnet 命令能做什么？dubbo 通过 telnet 命令来进行服务治理，具体使用看这篇文章《dubbo服务调试管理实用命令》。 telnet localhost 8090 26、Dubbo支持服务降级吗？Dubbo 2.2.0 以上版本支持。 27、Dubbo如何优雅停机？Dubbo 是通过 JDK 的 ShutdownHook 来完成优雅停机的，所以如果使用 kill -9 PID 等强制关闭指令，是不会执行优雅停机的，只有通过 kill PID 时，才会执行。 28、服务提供者能实现失效踢出是什么原理？服务失效踢出基于 Zookeeper 的临时节点原理。 29、如何解决服务调用链过长的问题？Dubbo 可以使用 Pinpoint 和 Apache Skywalking(Incubator) 实现分布式服务追踪，当然还有其他很多方案。 30、服务读写推荐的容错策略是怎样的？读操作建议使用 Failover 失败自动切换，默认重试两次其他服务器。 写操作建议使用 Failfast 快速失败，发一次调用失败就立即报错。 31、Dubbo必须依赖的包有哪些？Dubbo 必须依赖 JDK，其他为可选。 32、Dubbo的管理控制台能做什么？管理控制台主要包含：路由规则，动态配置，服务降级，访问控制，权重调整，负载均衡，等管理功能。 33、说说 Dubbo 服务暴露的过程。Dubbo 会在 Spring 实例化完 bean 之后，在刷新容器最后一步发布 ContextRefreshEvent 事件的时候，通知实现了 ApplicationListener 的 ServiceBean 类进行回调 onApplicationEvent 事件方法，Dubbo 会在这个方法中调用 ServiceBean 父类 ServiceConfig 的 export 方法，而该方法真正实现了服务的（异步或者非异步）发布。 34、Dubbo 停止维护了吗？2014 年开始停止维护过几年，17 年开始重新维护，并进入了 Apache 项目。 35、Dubbo 和 Dubbox 有什么区别？Dubbox 是继 Dubbo 停止维护后，当当网基于 Dubbo 做的一个扩展项目，如加了服务可 Restful 调用，更新了开源组件等。 Dubbo 2.6.1 是改变结构后首次发布的版本，Dubbo 2.6.0 已合并当当网提供的 Dubbox 分支。 Dubbo的版本策略：两个大版本并行发展，2.5.x是稳定版本，2.6.x是新功能实验版本。2.6上实验都稳定了以后，会迁移到2.5。 36、你还了解别的分布式框架吗？别的还有 Spring cloud、Facebook 的 Thrift、Twitter 的 Finagle 等。 37、Dubbo 能集成 Spring Boot 吗？可以的，项目地址如下。 https://github.com/apache/incubator-dubbo-spring-boot-project 38、在使用过程中都遇到了些什么问题？Dubbo 的设计目的是为了满足高并发小数据量的 rpc 调用，在大数据量下的性能表现并不好，建议使用 rmi 或 http 协议。 39、你读过 Dubbo 的源码吗？要了解 Dubbo 就必须看其源码，了解其原理，花点时间看下吧，网上也有很多教程，后续有时间我也会在公众号上分享 Dubbo 的源码。 40、你觉得用 Dubbo 好还是 Spring Cloud 好？扩展性的问题，没有好坏，只有适合不适合，不过我好像更倾向于使用 Dubbo, Spring Cloud 版本升级太快，组件更新替换太频繁，配置太繁琐，还有很多我觉得是没有 Dubbo 顺手的地方…… Java技术栈","link":"/2019/07/30/Dubbo知识精华-续/"},{"title":"redis","text":"1）Redis为什么使用单进程单线程方式也这么快Redis采用的是基于内存的采用的是单进程单线程模型的KV数据库，由C语言编写。官方提供的数据是可以达到100000+的qps。这个数据不比采用单进程多线程的同样基于内存的KV数据库Memcached差。 Redis快的主要原因是： 完全基于内存 数据结构简单，对数据操作也简单 使用多路 I/O 复用模型 多路 I/O 复用模型是利用select、poll、epoll可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。 和Memcached不同，Redis并没有直接使用Libevent，而是自己完成了一个非常轻量级的对select、epoll、evport、kqueue这些通用的接口的实现。在不同的系统调用选用适合的接口，linux下默认是epoll。因为Libevent比较重更通用代码量也就很庞大，拥有很多Redis用不上的功能，Redis为了追求“轻巧”并且去除依赖，就选择自己去封装了一套。 单进程单线程好处 代码更清晰，处理逻辑更简单 不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗 不存在多进程或者多线程导致的切换而消耗CPU 单进程单线程弊端无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善； 其他一些优秀的开源软件采用的模型 多进程单线程模型：Nginx 单进程多线程模型：Memcached 2）五种类型数据类型字符串、列表、散列表，集合、有序集合 3）内存中数据持久化使用复制来扩展读性能：复制到多台服务器、提高读性能和可用性 使用分区来扩展写性能【hash一致性算法】：当数据量大的时候,把数据分散存入多个数据库中,减少单节点的连接压力 特点 完全基于内存 数据结构简单，对数据操作也简单 使用多路 I/O 复用模型 4）Redis 适用场景 缓存 将热点数据放到内存中 消息队列 List 类型是双向链表，很适合用于消息队列 计数器 快速、频繁读写操作；string的单线性自增减 ++ – 共同好友关系 set 交集运算，很容易就可以知道用户的共同好友 排名 zset有序集合 5）持久化快照持久化 将某个时间点的所有数据都存放到硬盘上 可以将快照复制到其它服务器从而创建具有相同数据的服务器副本 缺点：故障可能丢失最后一次创建快照之后的数据；如果数据量很大，保存快照的时间也会很长。 AOF 持久化 将写命令添加到 AOF 文件（Append Only File）的末尾 always： 每个写命令都同步，严重减低服务器的性能； everysec ：每秒同步一次，比较合适，保证系统奔溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no ：让操作系统来决定何时同步，不能给性能带来提升，且会增加奔溃时数据丢失量 随着服务器写请求的增多，AOF 文件会越来越大；Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。 对硬盘的文件进行写入时，写入的内容首先会被存储到缓冲区，操作系统决定何时写 用户可以调用 file.flush() 方法请求尽快将缓冲区存储的数据同步到硬盘 redis主从复制 分布式数据同步方式 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。 一个从服务器只能有一个主服务器 从服务器连接主服务器的过程 主服务器创建快照文件，发送给从服务器。同时记录其间执行的写命令，发送完毕后，开始向从服务器发送写命令； 从服务器丢弃所有旧数据，载入主服务器的快照文件，然后开始接受主服务器发来的写命令； 主服务器每执行一次写命令，就向从服务器发送相同的写命令 主从链 创建一个中间层来分担主服务器的复制工作 随着负载不断上升，主服务器可能无法很快地更新所有从服务器 重新连接和重新同步从服务器将导致系统超载 中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器 6）redis 主服务器 故障 处理当主服务器出现故障时，Redis 常用的做法是新开一台服务器作为主服务器，具体步骤如下：假设 A 为主服务器，B 为从服务器，当 A 出现故障时，让 B 生成一个快照文件，将快照文件发送给 C，并让 C 恢复快照文件的数据。最后，让 B 成为 C 的从服务器。 7）分片 集群 读并发数据划分为多个部分，可以将数据存储到多台机器里，作用：负载均衡、线性级别的性能提升 8）分片方式：客户端代码分片 Redis Sharding，对Redis数据的key进行hash，相同的key到相同的节点上 一致性哈希算法 代理服务器分片 轮询round-bin 9）redis与数据库的同步 数据一致 一致性要求高场景，实时同步方案，即查询redis，若查询不到再从DB查询，保存到redis； 更新redis时，先更新数据库，再将redis内容设置为过期(建议不要去更新缓存内容，直接设置缓存过期)，再用ZINCRBY增量修正redis数据 并发程度高的，采用异步队列的方式，采用kafka等消息中间件处理消息生产和消费 阿里的同步工具canal，实现方式是模拟mysql slave和master的同步机制，监控DB bitlog的日志更新来触发redis的更新，解放程序员双手，减少工作量 利用mysql触发器的API进行编程,c/c++语言实现，学习成本高。 10）热数据与Mysql的同步编码实现 数据库上锁热点数据（经常会被查询，但是不经常被修改或者删除的数据），首选是使用redis缓存 用spring的AOP来构建redis缓存的自动生产和清除，过程如下： Select 数据库前查询redis，有的话使用redis数据，放弃select 数据库，没有的话，select 数据库，然后将数据插入redis update或者delete 数据库数据 高并发的情况下：先对数据库加锁，再删除redis 查询redis是否存在该数据，若存在则先对数据库加行锁，再删除redis，再update或者delete数据库中数据 update或者delete redis，先更新数据库，再将redis内容设置为过期(建议不要去更新缓存内容，直接设置缓存过期) 出错场景：update先删掉了redis中的该数据，这时另一个线程执行查询，发现redis中没有，瞬间执行了查询SQL，并且插入到redis 11）缓存穿透，缓存击穿，缓存雪崩解决方案分析缓存穿透缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 解决方案有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 缓存雪崩缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。 解决方案缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 缓存击穿对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。 缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 解决方案我们的目标是：尽量少的线程构建缓存(甚至是一个) + 数据一致性 + 较少的潜在危险 https://www.cnblogs.com/raichen/p/7750165.html","link":"/2019/07/30/Redis_hot/"},{"title":"为什么使用 Redis","text":"绝大部分写业务的程序员，在实际开发中使用 Redis 的时候，只会 Set Value 和 Get Value 两个操作，对 Redis 整体缺乏一个认知。这里对 Redis 常见问题做一个总结，解决大家的知识盲点。 1、为什么使用 Redis在项目中使用 Redis，主要考虑两个角度：性能和并发。如果只是为了分布式锁这些其他功能，还有其他中间件 Zookpeer 等代替，并非一定要使用 Redis。 性能：如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的 SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。 特别是在秒杀系统，在同一时间，几乎所有人都在点，都在下单。。。执行的是同一操作———向数据库查数据。 根据交互效果的不同，响应时间没有固定标准。在理想状态下，我们的页面跳转需要在瞬间解决，对于页内操作则需要在刹那间解决。 并发：如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用 Redis 做一个缓冲操作，让请求先访问到 Redis，而不是直接访问数据库。 使用 Redis 的常见问题 缓存和数据库双写一致性问题 缓存雪崩问题 缓存击穿问题 缓存的并发竞争问题 2、单线程的 Redis 为什么这么快这个问题是对 Redis 内部机制的一个考察。很多人都不知道 Redis 是单线程工作模型。 原因主要是以下三点：纯内存操作 单线程操作，避免了频繁的上下文切换 采用了非阻塞 I/O 多路复用机制 仔细说一说 I/O 多路复用机制，打一个比方：小名在 A 城开了一家快餐店店，负责同城快餐服务。小明因为资金限制，雇佣了一批配送员，然后小曲发现资金不够了，只够买一辆车送快递。 经营方式一客户每下一份订单，小明就让一个配送员盯着，然后让人开车去送。慢慢的小曲就发现了这种经营方式存在下述问题： 时间都花在了抢车上了，大部分配送员都处在闲置状态，抢到车才能去送。 随着下单的增多，配送员也越来越多，小明发现快递店里越来越挤，没办法雇佣新的配送员了。 配送员之间的协调很花时间。 综合上述缺点，小明痛定思痛，提出了经营方式二。 经营方式二小明只雇佣一个配送员。当客户下单，小明按送达地点标注好，依次放在一个地方。最后，让配送员依次开着车去送，送好了就回来拿下一个。上述两种经营方式对比，很明显第二种效率更高。 在上述比喻中： 每个配送员→每个线程 每个订单→每个 Socket(I/O 流) 订单的送达地点→Socket 的不同状态 客户送餐请求→来自客户端的请求 明曲的经营方式→服务端运行的代码 一辆车→CPU 的核数 于是有了如下结论： 经营方式一就是传统的并发模型，每个 I/O 流(订单)都有一个新的线程(配送员)管理。 经营方式二就是 I/O 多路复用。只有单个线程(一个配送员)，通过跟踪每个 I/O 流的状态(每个配送员的送达地点)，来管理多个 I/O 流。 下面类比到真实的 Redis 线程模型，如图所示： Redis-client 在操作的时候，会产生具有不同事件类型的 Socket。在服务端，有一段 I/O 多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。 3、Redis 的数据类型及使用场景一个合格的程序员，这五种类型都会用到。 String 最常规的 set/get 操作，Value 可以是 String 也可以是数字。一般做一些复杂的计数功能的缓存。 Hash 这里 Value 存放的是结构化的对象，比较方便的就是操作其中的某个字段。我在做单点登录的时候，就是用这种数据结构存储用户信息，以 CookieId 作为 Key，设置 30 分钟为缓存过期时间，能很好的模拟出类似 Session 的效果。 List 使用 List 的数据结构，可以做简单的消息队列的功能。另外，可以利用 lrange 命令，做基于 Redis 的分页功能，性能极佳，用户体验好。 Set 因为 Set 堆放的是一堆不重复值的集合。所以可以做全局去重的功能。我们的系统一般都是集群部署，使用 JVM 自带的 Set 比较麻烦。另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。 Sorted Set Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。可以做排行榜应用，取 TOP N 操作。Sorted Set 可以用来做延时任务。 4、Redis 的过期策略和内存淘汰机制Redis 是否用到家，从这就能看出来。比如你 Redis 只能存 5G 数据，可是你写了 10G，那会删 5G 的数据。怎么删的，这个问题思考过么？ 正解：Redis 采用的是定期删除+惰性删除策略。 为什么不用定时删除策略 定时删除，用一个定时器来负责监视 Key，过期则自动删除。虽然内存及时释放，但是十分消耗 CPU 资源。在大并发请求下，CPU 要将时间应用在处理请求，而不是删除 Key，因此没有采用这一策略。 定期删除+惰性删除如何工作 定期删除，Redis 默认每个 100ms 检查，有过期 Key 则删除。需要说明的是，Redis 不是每个 100ms 将所有的 Key 检查一次，而是随机抽取进行检查。如果只采用定期删除策略，会导致很多 Key 到时间没有删除。于是，惰性删除派上用场。 采用定期删除+惰性删除就没其他问题了么 不是的，如果定期删除没删除掉 Key。并且你也没及时去请求 Key，也就是说惰性删除也没生效。这样，Redis 的内存会越来越高。那么就应该采用内存淘汰机制。 在 redis.conf 中有一行配置： maxmemory-policy volatile-lru该配置就是配内存淘汰策略的： noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。（推荐使用，目前项目在用这种）(最近最久使用算法) allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。（应该也没人用吧，你不删最少使用 Key，去随机删） volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。（不推荐） volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。（依然不推荐） volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。（不推荐） 5、Redis 和数据库双写一致性问题一致性问题还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。前提是如果对数据有强一致性要求，不能放缓存。我们所做的一切，只能保证最终一致性。 另外，我们所做的方案从根本上来说，只能降低不一致发生的概率。因此，有强一致性要求的数据，不能放缓存。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。 6、如何应对缓存穿透和缓存雪崩问题这两个问题，一般中小型传统软件企业很难碰到。如果有大并发的项目，流量有几百万左右，这两个问题一定要深刻考虑。缓存穿透，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。 缓存穿透解决方案： 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。 采用异步更新策略，无论 Key 是否取到值，都直接返回。Value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的 Key。迅速判断出，请求所携带的 Key 是否合法有效。如果不合法，则直接返回。 缓存雪崩，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。 缓存雪崩解决方案： 给缓存的失效时间，加上一个随机值，避免集体失效。 使用互斥锁，但是该方案吞吐量明显下降了。 双缓存。我们有两个缓存，缓存 A 和缓存 B。缓存 A 的失效时间为 20 分钟，缓存 B 不设失效时间。自己做缓存预热操作。 然后细分以下几个小点：从缓存 A 读数据库，有则直接返回；A 没有数据，直接从 B 读数据，直接返回，并且异步启动一个更新线程，更新线程同时更新缓存 A 和缓存 B。 7、如何解决 Redis 的并发竞争 Key 问题这个问题大致就是，同时有多个子系统去 Set 一个 Key。这个时候要注意什么呢？大家基本都是推荐用 Redis 事务机制。 但是我并不推荐使用 Redis 的事务机制。因为我们的生产环境，基本都是 Redis 集群环境，做了数据分片操作。你一个事务中有涉及到多个 Key 操作的时候，这多个 Key 不一定都存储在同一个 redis-server 上。因此，Redis 的事务机制，十分鸡肋。 如果对这个 Key 操作，不要求顺序这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做 set 操作即可，比较简单。 如果对这个 Key 操作，要求顺序假设有一个 key1，系统 A 需要将 key1 设置为 valueA，系统 B 需要将 key1 设置为 valueB，系统 C 需要将 key1 设置为 valueC。 期望按照 key1 的 value 值按照 valueA &gt; valueB &gt; valueC 的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。 假设时间戳如下：系统 A key 1 {valueA 3:00}系统 B key 1 {valueB 3:05}系统 C key 1 {valueC 3:10} 那么，假设系统 B 先抢到锁，将 key1 设置为{valueB 3:05}。接下来系统 A 抢到锁，发现自己的 valueA 的时间戳早于缓存中的时间戳，那就不做 set 操作了，以此类推。其他方法，比如利用队列，将 set 方法变成串行访问也可以。 8、总结Redis 在国内各大公司都能看到其身影，比如我们熟悉的新浪，阿里，腾讯，百度，美团，小米等。学习 Redis，这几方面尤其重要：Redis 客户端、Redis 高级功能、Redis 持久化和开发运维常用问题探讨、Redis 复制的原理和优化策略、Redis 分布式解决方案等。 转自：https://www.cnblogs.com/yaodengyan/p/9717080.html","link":"/2019/07/30/为什么我们做分布式使用Redis/"}],"tags":[{"name":"dubbo","slug":"dubbo","link":"/tags/dubbo/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"消息中间件","slug":"消息中间件","link":"/tags/消息中间件/"}],"categories":[{"name":"dubbo","slug":"dubbo","link":"/categories/dubbo/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"MQ","slug":"MQ","link":"/categories/MQ/"}]}